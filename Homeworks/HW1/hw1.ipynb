{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: A little review\n",
    "\n",
    "## Due Date: Tuesday, October 7th, 11:59PM\n",
    "\n",
    "Welcome to the first homework of 311! All homeworks will be due by 11:59pm on the Monday following their assignment. The objective with this assignment is to refresh some concepts and practices from DSCI101/102**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborators: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Grading is broken down into autograded answers and free response. \n",
    "\n",
    "For autograded answers, the results of your code are compared to provided and/or hidden tests. For most homeworks, the autograder will **only tell you whether your response is potentially correct** *i.e.* within a realistic range of values or of the correct value type. This is to help you avoid any unintended obvious errors, but won't tell you if your answer is correct.\n",
    "\n",
    "For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question. Now that you're in upper-divisional core coursework, there will be many more of these. \n",
    "\n",
    "For plots, make sure to be as descriptive as possible: include titles, axes labels, and units wherever applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators, if any**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "\n",
    "path = 'https://github.com/oregon-data-science/DSCI101/raw/main/data/'\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the review then.\n",
    "\n",
    "## p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Run the next cell</font>\n",
    "\n",
    "Define the following functions. You will use `fitted_value` for question 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'functions defined'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_units(numbers):\n",
    "    ''' Given numbers array return z_array in standard units'''\n",
    "    z_array = (numbers - np.mean(numbers)) / np.std(numbers)\n",
    "    return z_array\n",
    "\n",
    "def correlation(table, label_x, label_y):\n",
    "    ''' Returns r, correlation of the 2 arrays  '''\n",
    "    r = np.mean(standard_units(table[label_x]) * \n",
    "                standard_units(table[label_y]))\n",
    "    return r\n",
    "\n",
    "def slope(table, label_x, label_y):\n",
    "    ''' Return slope of correlation line in original units'''\n",
    "    r = correlation(table, label_x, label_y)\n",
    "    return r * np.std(table[label_y]) / np.std(table[label_x])\n",
    "\n",
    "def intercept(table, label_x, label_y):\n",
    "    ''' return the y intercept in original units'''\n",
    "    b = (np.mean(table[label_y]) - \n",
    "         slope(table, label_x, label_y) * np.mean(table[label_x]))\n",
    "    return b\n",
    "\n",
    "def fitted_value(table, label_x, label_y, given_x):\n",
    "    ''' Fit given_x (a specific x value), predicts the specific y value'''\n",
    "    m = slope(table, label_x, label_y)\n",
    "    b = intercept(table, label_x, label_y)\n",
    "    predicted_y = m * given_x + b    \n",
    "    return predicted_y\n",
    "\n",
    "'functions defined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/oregon-data-science/DSCI101/raw/main/images/640px-American_roulette_wheel_layout.png' width='250'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roulette wheels like the one above have 38 places the roulette ball may land in:  \n",
    "2 green, or   \n",
    "18 red, or   \n",
    "18 black places.\n",
    "    \n",
    "With many rolls, you would expect to get red about 18 times out of every 38 rolls.\n",
    "\n",
    "You need to determine if a wheel that was rolled 100 times and resulted in red 61 times is a fair wheel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "\n",
    "What is the **\"null hypothesis**\" regarding the roulette wheel in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response**: The roullete wheel is fair, where the probabilty of of landing on red is p = 18/38. The observed difference where we landed on red 61/100 times is due to chance/randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2\n",
    "\n",
    "Create a model_proportions array that you can use with the **sample_proportions** function to bet red on the roulette wheel **100 times**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47368421, 0.47368421, 0.05263158])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = 18\n",
    "black = 18\n",
    "green = 2\n",
    "total = 38\n",
    "\n",
    "# Create model_proportions as a numpy array\n",
    "model_proportions = np.array([red/total, black/total, green/total])\n",
    "model_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_2</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q1_2 results: All test cases passed!"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed number of reds in 100 spins (61) is higher than the expected proportion. Might this be due to chance, or do we think we're playing with an unfair wheel? Let's perform a simulation. Simulate 1000 repetitions of 100 spins of the roulette wheel assuming the null hypothesis, determine the proportion of reds in each 100-spin sample, then compute the corresponding p-value. You will define two functions to do so: `sample_proportions` and `play_roulette`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3\n",
    "\n",
    "You may remember the function `sample_proportions` from the `datascience` package in 101/102. Because we've moved on from that package, you will now define the function yourself. Your function should take two arguments: an array of proportions (as in the form of `model_proportions`), and the number of random samples (roulette rolls) to take from the provided proportions. It should return an array of the estimated proportions of each color based on your sampling. \n",
    "\n",
    "*hint:* There are a few different ways you can create this function, but it might be helpful to use the function `np.random.choice`. You can look at its help file for usage examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample_proportions\n",
    "def sample_proportions(proportions, spins):\n",
    "    p = np.asarray(proportions, dtype=float)\n",
    "    draws = np.random.choice(len(p), size=spins, p=p)   # indices 0..len(p)-1\n",
    "    counts = np.bincount(draws, minlength=len(p))\n",
    "    return counts / spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46, 0.5 , 0.04])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_proportions(model_proportions, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_3</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q1_3 results: All test cases passed!"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.4\n",
    "\n",
    "Now define `play_roulette`. Your function should take one argument: the number of repetitions in our simulation. It should return an array of sampled red proportions of length equal to the number of repetitions. Use `model_proportions` in your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48, 0.54, 0.6 , 0.51, 0.39, 0.49, 0.46, 0.5 , 0.51, 0.5 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def play_roulette(repetitions):\n",
    "    red_results = np.array([\n",
    "        sample_proportions(model_proportions, 100)[0]\n",
    "        for _ in range(repetitions)\n",
    "    ])\n",
    "    return red_results\n",
    "\n",
    "\n",
    "# Run the simulation 1000 times\n",
    "simulated_reds = play_roulette(1000)\n",
    "simulated_reds[:10]  # optional preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_4</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q1_4 results: All test cases passed!"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.5\n",
    "\n",
    "Determine the **proportion** of times the number of simulated reds was greater than the observed reds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the p_value given an observed value\n",
    "observed_reds = 61/100\n",
    "\n",
    "prop_red_greater = np.count_nonzero(simulated_reds > observed_reds) / len(simulated_reds)\n",
    "prop_red_greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this proportion mean with respect to our hypotheses? Based on your answer, would you reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response:**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_5</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q1_5 results: All test cases passed!"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next series of questions will test your conceptual understanding of some of the most important topics covered in the 101/102 series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1\n",
    "\n",
    "We wish to evaluate the effect of maternal smoking habit on the birth weight of newborns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m baby = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbaby.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mBirth Weight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMaternal Smoker\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      2\u001b[39m baby.head(\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1405\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1392\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1393\u001b[39m     dialect,\n\u001b[32m   1394\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1401\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1402\u001b[39m )\n\u001b[32m   1403\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1968\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1965\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1966\u001b[39m         new_col_dict = col_dict\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m     df = \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1975\u001b[39m     \u001b[38;5;28mself\u001b[39m._currow += new_rows\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/internals/construction.py:443\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     arrays = \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     missing = arrays.isna()\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    446\u001b[39m         \u001b[38;5;66;03m# GH10856\u001b[39;00m\n\u001b[32m    447\u001b[39m         \u001b[38;5;66;03m# raise ValueError if only scalars in dict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/series.py:493\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    490\u001b[39m name = ibase.maybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     index = \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    496\u001b[39m     dtype = \u001b[38;5;28mself\u001b[39m._validate_dtype(dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7713\u001b[39m, in \u001b[36mensure_index\u001b[39m\u001b[34m(index_like, copy)\u001b[39m\n\u001b[32m   7711\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex.from_arrays(index_like)\n\u001b[32m   7712\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m7713\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtupleize_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   7714\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:566\u001b[39m, in \u001b[36mIndex.__new__\u001b[39m\u001b[34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[39m\n\u001b[32m    563\u001b[39m         data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     arr = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mindex must be specified when data is not list-like\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/construction.py:651\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    648\u001b[39m     subarr = _try_cast(data, dtype, copy)\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     subarr = \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m subarr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    653\u001b[39m         subarr = cast(np.ndarray, subarr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:138\u001b[39m, in \u001b[36mmaybe_convert_platform\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.dtype == _dtype_obj:\n\u001b[32m    137\u001b[39m     arr = cast(np.ndarray, arr)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     arr = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2555\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_objects\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "source": [
    "baby = pd.read_table(path+'baby.csv', sep = \",\")[[\"Birth Weight\", \"Maternal Smoker\"]]\n",
    "baby.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we shuffle the smoker column with respect to maternal birth weight. Why? Assign your selection to `q2_1` below. \n",
    "\n",
    "1) This is one step in splitting the data into train/test sets\n",
    "\n",
    "2) This lets us simulate the test statistic under the null hypothesis. \n",
    "\n",
    "3) Maternal smoking habit is a confounding variable we wish to control for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2\n",
    "\n",
    "You are a summer intern with a group that has some donor funding. They spent $10,000 to gather data from a **representative random sample of 500** responses from the local community. Problem: the **standard deviation of the data is far too large** to confidently describe the local community.\n",
    "\n",
    "They would like to reduce the standard deviation to **about one third** of what it is now. They hope that for a total cost of $30,000 they can get a total of 1500 responses.\n",
    "\n",
    "How will tripling your sample size affect your standard deviation? What would you recommend to your donors based on your answer? Feel free to use code to help you answer this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3\n",
    "\n",
    "We have data and wish to train a predictive model by splitting it into 2 parts (training and testing). We take the first 90 rows of data as training, the rest as testing.\n",
    "\n",
    "Are there any problems with this approach? If so, what would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.4\n",
    "\n",
    "You and your lab partner are working with data from several columns. You want to predict some response variable and have two distinct linear models, one for each predictor. What is most appropriate way to compare the fit of the two models? Assign your answer to `q2_4` below.\n",
    "\n",
    "1) Compute the sum of the residuals to compare the two models\n",
    "\n",
    "2) Visually assess the fit of the two lines to the data\n",
    "\n",
    "3) Compute mean squared error to compare the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.5\n",
    "\n",
    "Which of the following is true about the **Central Limit Theorem**? There is only one correct answer. Assign your answer to q2_5 below. \n",
    "\n",
    "1) Given a large enough sample size, any variable will become approximately normally distributed. \n",
    "\n",
    "2) Given a large enough sample size, the estimated mean of a population will be drawn from an approximately normal distribution. \n",
    "\n",
    "3) Confidence in a sample statistic can only be estimated from normally distributed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.6\n",
    "\n",
    "A 2022 review of COVID rapid tests in Europe reported an approximate 10% false positive rate, and a 20% false negative rate. 1000 individuals with COVID-like symptoms, 300 of whom actually have COVID, test themselves. Would we expect that there will be more people without COVID that test positive, or more people that have COVID but test negative. Assign your answer to q2_6 below. \n",
    "\n",
    "1) More people without COVID that test positive\n",
    "\n",
    "2) More people with COVID that test negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.7\n",
    "\n",
    "Underdiagnosis of a medical condition is when the majority of individuals in a population with a condition aren't diagnosed with the condition.\n",
    "\n",
    "Overdiagnosis is when the majority of those diagnosed with a condition shouldn't have been diagnosed with the condition. \n",
    "\n",
    "In the adult population in the U.S., it is estimated that ~3% of individuals have ADHD. Let's assume that 60% of invididuals with ADHD decide to get evaluated, while 10% without ADHD think they may have the condition and also decide to get evaluated. The evaluation process is variable and prone to error. On average, ADHD evaluation has a 20% false negative rate and a 20% false positive rate. These approximate estimates come from a [meta-analysis on adult ADHD assessment](https://www.sciencedirect.com/science/article/pii/S0891422210003264?casa_token=4X4o0NmEjf0AAAAA:fTcQ4VkVh1Oz5Ze73HG5ljGac9Aiyz2rrI8hS9U27PTty9Q7DcdOMbqyNOSgX4dljNU_QDiwqDU#bib0010) (a meta-analysis is a study of studies). \n",
    "\n",
    "Is ADHD in the adult population underdiagnosed, overdiagnosed, or both? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.8\n",
    "\n",
    "Read in the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dugongs = pd.read_table(path + 'dugongs.csv', sep = \",\")\n",
    "dugongs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between dugong length and their age\n",
    "sns.relplot(data = dugongs, x = \"Age\", y = \"Length\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `fitted_values()` defined above, predict the length of a dugong of that's 7 years old. Do the same for a dugong 50 years old.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dugong_7 = ...\n",
    "dugong_50 = ...\n",
    "dugong_7\n",
    "dugong_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q2_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.9\n",
    "\n",
    "Based on visual assessment of the relationship between dugong age and length, do you think the estimate for a 7-year old dugong is a good one. What about the estimate for a 50-year old dugong? Explain your answer to each below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order. Then execute the following two commands from the File menu:\n",
    "\n",
    "* Save and Checkpoint\n",
    "* Close and Halt\n",
    "\n",
    "Then upload your .ipynb file to Canvas assignment HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
